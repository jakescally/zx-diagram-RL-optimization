{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555bbd5d-2be1-492e-926e-a366b0392ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import os\n",
    "import pyzx as zx\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Set the number of threads PyTorch can use for CPU operations\n",
    "torch.set_num_threads(16)  # Set this to the number of threads you want to use\n",
    "\n",
    "# Optionally, set the number of interop threads (for inter-op parallelism)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ed8ae-2e3d-4e80-8758-54ab0e4f3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc checking functions\n",
    "\n",
    "def is_hadamard_edge(g, edge):\n",
    "    return g.edge_type(edge) == zx.EdgeType.HADAMARD\n",
    "\n",
    "def is_hadamard_edgeV(g, v1, v2):\n",
    "    if g.connected(v1, v2):\n",
    "        edge = g.edge(v1, v2)\n",
    "        return g.edge_type(edge) == zx.EdgeType.HADAMARD\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def can_fuse(g, edge):\n",
    "    v1, v2 = g.edge_st(edge)\n",
    "    return g.type(v1) == g.type(v2)\n",
    "\n",
    "def get_pivot_verts(g):\n",
    "    vertex_set = set()\n",
    "    matches = zx.rules.match_pivot_parallel(g)\n",
    "    for match in matches:\n",
    "        v1, v2, _, _ = match\n",
    "        vertex_set.add(v1)\n",
    "        vertex_set.add(v2)\n",
    "\n",
    "    return vertex_set\n",
    "\n",
    "def get_fusion_verts(g):\n",
    "    fusions = set()\n",
    "    # loop through all EDGES in the graph\n",
    "    for edge in g.edges():\n",
    "        # get the vertices of the current edge\n",
    "        v1, v2 = edge\n",
    "        type1 = g.type(v1)\n",
    "        type2 = g.type(v2) # note the types of vertex\n",
    "        # make sure the edge isn't hadamard\n",
    "        if g.edge_type(edge) != zx.EdgeType.HADAMARD:\n",
    "            # make sure neither vertex is a boundary\n",
    "            if type1 != zx.VertexType.BOUNDARY and type2 != zx.VertexType.BOUNDARY:\n",
    "                # check if they can fuse (same spider type)\n",
    "                if type1 == type2:\n",
    "                    fusions.add(v1)\n",
    "                    fusions.add(v2)\n",
    "\n",
    "    return fusions\n",
    "    \n",
    "def get_lcomp_verts(g):\n",
    "    matches = zx.rules.match_lcomp_parallel(g)\n",
    "    vertex_set = set()\n",
    "\n",
    "    for match in matches:\n",
    "        v1, neighbors = match \n",
    "        vertex_set.add(v1)\n",
    "        for vert in neighbors:\n",
    "            vertex_set.add(vert)\n",
    "\n",
    "    return list(vertex_set)\n",
    "\n",
    "def get_bialg_verts(g):\n",
    "    matches = zx.rules.match_bialg_parallel(g)\n",
    "    vertex_set = set()\n",
    "    for match in matches:\n",
    "        v1, v2, _, _ = match\n",
    "        vertex_set.add(v1)\n",
    "        vertex_set.add(v2)\n",
    "\n",
    "    return list(vertex_set)\n",
    "\n",
    "def get_supp_verts(g):\n",
    "    matches = zx.rules.match_supplementarity(g)\n",
    "    vertex_set = set()\n",
    "    for match in matches:\n",
    "        v1, v2, _, _ = match\n",
    "        vertex_set.add(v1)\n",
    "        vertex_set.add(v2)\n",
    "    return vertex_set\n",
    "\n",
    "def get_fusion_vert_pairs(g: zx.Graph):\n",
    "    fusions = set()\n",
    "    # loop through all EDGES in the graph\n",
    "    for edge in g.edges():\n",
    "        # get the vertices of the current edge\n",
    "        v1, v2 = edge\n",
    "        type1 = g.type(v1)\n",
    "        type2 = g.type(v2) # note the types of vertex\n",
    "        # make sure the edge isn't hadamard\n",
    "        if g.edge_type(edge) != zx.EdgeType.HADAMARD:\n",
    "            # make sure neither vertex is a boundary\n",
    "            if type1 != zx.VertexType.BOUNDARY and type2 != zx.VertexType.BOUNDARY:\n",
    "                # check if they can fuse (same spider type)\n",
    "                if type1 == type2:\n",
    "                    fusions.add((v1,v2))\n",
    "    \n",
    "    return fusions\n",
    "\n",
    "def color_change(g, v):\n",
    "    vtype = g.type(v)\n",
    "    if vtype == zx.VertexType.BOUNDARY:\n",
    "        return False\n",
    "    neighbors = g.neighbors(v)\n",
    "    for neighbor in neighbors:\n",
    "        edge = g.edge(v, neighbor)\n",
    "        etype = g.edge_type(edge)\n",
    "        if etype == zx.EdgeType.HADAMARD:\n",
    "            g.set_edge_type(edge, zx.EdgeType.SIMPLE)\n",
    "        elif etype == zx.EdgeType.SIMPLE:\n",
    "            g.set_edge_type(edge, zx.EdgeType.HADAMARD)\n",
    "    if vtype == zx.VertexType.X:\n",
    "        g.set_type(v, zx.VertexType.Z)\n",
    "        return True\n",
    "    elif vtype == zx.VertexType.Z:\n",
    "        g.set_type(v, zx.VertexType.X)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9670f75-b239-4c73-b793-5289d4a7df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph representation class\n",
    "class ZXGraphRepresentation:\n",
    "    def __init__(self, g: zx.Graph):\n",
    "        # super(ZXGraphRepresentation, self).__init__()\n",
    "        self.g = g\n",
    "        self.node_features = self.get_node_features()\n",
    "        self.edge_features, self.edge_index = self.get_edge_features()\n",
    "        self.action_features = self.get_action_features()\n",
    "\n",
    "    def get_node_features(self):\n",
    "        node_features = []\n",
    "\n",
    "        pivots = get_pivot_verts(self.g)\n",
    "        lcomps = get_lcomp_verts(self.g)\n",
    "        bialgs = get_bialg_verts(self.g)\n",
    "        fusions = get_fusion_verts(self.g)\n",
    "        supps = get_supp_verts(self.g)\n",
    "\n",
    "        # debugging\n",
    "        # print(f\"length of g.verices {len(self.g.vertices())}\")\n",
    "        # print(f\"g.vertices {self.g.vertices}\")\n",
    "\n",
    "        length = 0\n",
    "        vertices_test = self.g.vertices()\n",
    "        # print(f\"vertices right before looping: {vertices_test}\")\n",
    "        for v in self.g.vertices():\n",
    "            feature_vect = [0]*12 # [node_type, degree, phase, hadamard_count, fuse_count, pivot_possible, lcomp_possible, bialg_possible, fusion_possible, supp_involved, color_changeable, stop]\n",
    "    \n",
    "            # set node type 0 for Z, 1 for X, 2 for boundary\n",
    "            if self.g.type(v) == zx.VertexType.Z:\n",
    "                feature_vect[0] = 0\n",
    "            elif self.g.type(v) == zx.VertexType.X:\n",
    "                feature_vect[0] = 1\n",
    "            elif self.g.type(v) == zx.VertexType.BOUNDARY:\n",
    "                feature_vect[0] = 2\n",
    "            else:\n",
    "                feature_vect[0] = 9\n",
    "    \n",
    "            feature_vect[1] = len(self.g.neighbors(v))\n",
    "            feature_vect[2] = self.g.phase(v)\n",
    "\n",
    "            hadamard_count = sum(is_hadamard_edgeV(self.g, v, neighbor) for neighbor in self.g.neighbors(v))\n",
    "            feature_vect[3] = hadamard_count\n",
    "\n",
    "            fuse_count = 0\n",
    "            for neighbor in self.g.neighbors(v):\n",
    "                if self.g.type(v) == self.g.type(neighbor):\n",
    "                    fuse_count += 1\n",
    "\n",
    "            feature_vect[4] = fuse_count\n",
    "\n",
    "            feature_vect[5] = 1 if v in pivots else 0\n",
    "            feature_vect[6] = 1 if v in lcomps else 0\n",
    "            feature_vect[7] = 1 if v in bialgs else 0\n",
    "            feature_vect[8] = 1 if v in fusions else 0\n",
    "            feature_vect[9] = 1 if v in supps else 0\n",
    "            if self.g.type(v) != zx.VertexType.BOUNDARY:\n",
    "                feature_vect[10] = 1\n",
    "            else:\n",
    "                feature_vect[10] = 0\n",
    "            feature_vect[11] = 1\n",
    "    \n",
    "            node_features.append(feature_vect)\n",
    "            length+=1\n",
    "\n",
    "        # print(f\"length: {length}\")\n",
    "        out = torch.tensor(node_features, dtype=torch.float)\n",
    "        # print(f\"shape of ZXGR feature tensor: {out.shape}\")\n",
    "        # print(f\"node feature tensor in ZXGR: {out}\")\n",
    "        return out\n",
    "\n",
    "    def get_edge_features(self):\n",
    "        edge_features = []\n",
    "        edge_indices = []\n",
    "    \n",
    "        for edge in self.g.edges():\n",
    "            source, target = self.g.edge_st(edge)\n",
    "    \n",
    "            feature_vect = [0]*2 # [Hadamard, Fuseable]\n",
    "            feature_vect[0] = 1 if is_hadamard_edge(self.g, edge) else 0\n",
    "            feature_vect[1] = 1 if can_fuse(self.g, edge) else 0\n",
    "    \n",
    "            edge_features.append(feature_vect)\n",
    "            edge_indices.append([source,target])\n",
    "    \n",
    "        edge_features_tensor = torch.tensor(edge_features, dtype=torch.float)\n",
    "        edge_indices_tensor = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        # print(f\"EDGE INDICES TENSOR: {edge_indices_tensor}\")\n",
    "        # print(f\"EDGE FEATURES TENSOR: {edge_features_tensor}\")\n",
    "    \n",
    "        return edge_features_tensor, edge_indices_tensor\n",
    "\n",
    "    def get_action_features(self):\n",
    "        action_features = []\n",
    "\n",
    "        pivot_set = get_pivot_verts(self.g)\n",
    "        lcomp_set = get_lcomp_verts(self.g)\n",
    "        bialg_set = get_bialg_verts(self.g)\n",
    "        \n",
    "        for v in self.g.vertices():\n",
    "            feature_vect = [0]*3 # [pivot, lcomp, bialgebra]\n",
    "            feature_vect[0] = 1 if v in pivot_set else 0\n",
    "            feature_vect[1] = 1 if v in lcomp_set else 0\n",
    "            feature_vect[2] = 1 if v in bialg_set else 0\n",
    "            \n",
    "            action_features.append(feature_vect)\n",
    "    \n",
    "        return torch.tensor(action_features, dtype=torch.float)\n",
    "\n",
    "    def get_graph_data(self):\n",
    "        return Data(x=self.node_features, edge_index=self.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c3b72-8704-4581-8e23-1d82aa87d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the environment\n",
    "class ZXEnv():\n",
    "    def __init__(self, g: zx.Graph, num_qubits, num_gates, MAX_STEPS=100):\n",
    "        self.g = g\n",
    "        self.MAX_STEPS = MAX_STEPS\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_gates = num_gates\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.possible_actions = self._get_possible_actions()\n",
    "        self.num_actions = len(self.possible_actions)\n",
    "\n",
    "    def reset(self):\n",
    "        # resets the environment to the initial state, which in this case will be a random zx graph\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.g = zx.generate.CNOT_HAD_PHASE_circuit(self.num_qubits, self.num_gates).to_graph()\n",
    "        self.possible_actions = self._get_possible_actions()\n",
    "        self._update_action_space()\n",
    "        \n",
    "        return self.g\n",
    "\n",
    "    def _get_possible_actions(self):\n",
    "        actions = []\n",
    "        # put together all possible actions and matches for each step\n",
    "        # pivot, lcomp, bialgebra, fusion, supp, color change, [unfuse?]\n",
    "        \n",
    "        p_matches = zx.rules.match_pivot_parallel(self.g)\n",
    "        for match in p_matches:\n",
    "            actions += [('pivot', match)]\n",
    "\n",
    "        lc_matches = zx.rules.match_lcomp_parallel(self.g)\n",
    "        for match in lc_matches:\n",
    "            actions += [('lcomp', match)]\n",
    "\n",
    "        bialg_matches = zx.rules.match_bialg_parallel(self.g)\n",
    "        for match in bialg_matches:\n",
    "            actions += [('bialg', match)]\n",
    "\n",
    "        fusion_matches = get_fusion_vert_pairs(self.g)\n",
    "        for match in fusion_matches:\n",
    "            actions += [('fusion', match)]\n",
    "\n",
    "        supp_matches = zx.rules.match_supplementarity(self.g)\n",
    "        for match in supp_matches:\n",
    "            actions += [('supp', match)]\n",
    "\n",
    "        for v in self.g.vertices():\n",
    "            actions += [('color', v)]\n",
    "            # actions += [('unfuse', v)]\n",
    "\n",
    "        actions += [('stop', None)]\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def step(self, action):\n",
    "        past_node_count = len(self.g.vertices())\n",
    "        action_type, match = action\n",
    "\n",
    "        if action_type == 'pivot':\n",
    "            zx.rules.apply_rule(self.g, zx.rules.pivot, [match])\n",
    "        elif action_type == 'lcomp':\n",
    "            zx.rules.apply_rule(self.g, zx.rules.lcomp, [match])\n",
    "        elif action_type == 'bialg':\n",
    "            zx.rules.apply_rule(self.g, zx.rules.bialg, [match])\n",
    "        elif action_type == 'fusion':\n",
    "            zx.rules.apply_rule(self.g, zx.rules.spider, [match])\n",
    "        elif action_type == 'supp':\n",
    "            zx.rules.apply_rule(self.g, zx.rules.apply_supplementarity, [match])\n",
    "        elif action_type == 'color':\n",
    "            color_change(self.g, match)\n",
    "    \n",
    "\n",
    "        zx.rules.apply_rule(self.g, zx.rules.remove_ids, zx.rules.match_ids_parallel(self.g))\n",
    "        \n",
    "        reward = past_node_count - len(self.g.vertices())\n",
    "        self.current_step += 1\n",
    "\n",
    "        if self.current_step >= self.MAX_STEPS:\n",
    "            self.done = True\n",
    "\n",
    "        return self.g, reward, self.done, {}\n",
    "\n",
    "    def _update_action_space(self):\n",
    "        self.num_actions = len(self.possible_actions)\n",
    "\n",
    "    def render(self):\n",
    "        labels = {v: f\"Vertex {i}\" for i, v in enumerate(self.g.vertices())}\n",
    "        zx.draw(self.g, labels=labels)\n",
    "        \n",
    "    def close(self):\n",
    "        pass        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358741a0-c80a-4dd6-9e38-4e6dd9690195",
   "metadata": {},
   "outputs": [],
   "source": [
    "zx_graph = zx.generate.CNOT_HAD_PHASE_circuit(5,25).to_graph()\n",
    "test_env = ZXEnv(zx_graph,5,25)\n",
    "test_env.render()\n",
    "zx_rep = ZXGraphRepresentation(zx_graph)\n",
    "graph_data = zx_rep.get_graph_data()\n",
    "print(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fa3dc-6ef2-48f3-8dff-680fdbc598e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single gcn layer class\n",
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        # define a gcn convolution layer\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x is a node feature matrix, of dimensions [num_nodes, node_features]\n",
    "        # edge_index is a tensor that tells the GCN which nodes are connected\n",
    "        # and has dimensions [2, num_edges]\n",
    "\n",
    "        # a first layer aggregates features from its direct neighbors\n",
    "        # a second layer would be aggregating features from neighbors of neighbors\n",
    "        # and so on\n",
    "        \n",
    "        # perform a convolution\n",
    "        # print(f\"Shape of x: {x.shape}\")\n",
    "        # print(f\"x itself: {x}:\")\n",
    "        # print(f\"Shape of edge_index: {edge_index.shape}\")\n",
    "        # print(f\"edge_index itself: {edge_index}\")\n",
    "        x = self.conv(x, edge_index)\n",
    "        # apply a non-linear activation function\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc5c73-7f68-4f41-b7c2-c984ca98ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcn model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # create list of GCN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNLayer(input_dim, hidden_dim))\n",
    "        # add middle (hidden) layers\n",
    "        for _ in range(1, num_layers-1):\n",
    "            self.convs.append(GCNLayer(hidden_dim, hidden_dim))\n",
    "        # add final layer\n",
    "        self.convs.append(GCNLayer(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index) # convolve the nodes and edges\n",
    "            if i != self.num_layers - 1:\n",
    "                x = F.relu(x) # activation function on the last layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbd902-9f45-4e56-952a-bca9701c4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the model\n",
    "input_dim = 12 # feature vector\n",
    "hidden_dim = 12\n",
    "output_dim = 7 # possible actions [pivot, lcomp, bialg, fusion, supp, color, stop]\n",
    "num_layers = 1\n",
    "\n",
    "gcn_model = GCN(input_dim, hidden_dim, output_dim, num_layers=num_layers)\n",
    "\n",
    "zx_graph = zx.generate.CNOT_HAD_PHASE_circuit(2, 1).to_graph()\n",
    "zx.draw(zx_graph)\n",
    "zx_rep = ZXGraphRepresentation(zx_graph)\n",
    "graph_data = zx_rep.get_graph_data()\n",
    "print(f\"Input: {graph_data.x}\")\n",
    "\n",
    "\n",
    "node_embeddings = gcn_model(graph_data.x, graph_data.edge_index)\n",
    "print(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa9b9b-7f25-41f6-bb2a-57955f58b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNPolicyNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GCNPolicyNetwork, self).__init__()\n",
    "        self.gcn = GCN(input_dim, hidden_dim, output_dim, num_layers)\n",
    "        self.fc = torch.nn.Linear(output_dim, output_dim) # we want 6 logits (one for each possible action)\n",
    "\n",
    "    def forward(self, graph_data):\n",
    "        # print(f\"Graph data: {graph_data.x}, graph_data.edge_index: {graph_data.edge_index}\")\n",
    "        node_embeddings = self.gcn(graph_data.x, graph_data.edge_index)\n",
    "        action_logits = self.fc(node_embeddings)\n",
    "        action_logits = torch.softmax(action_logits, dim=1)\n",
    "        return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc2df6-09d0-4e4f-a71e-669f690a181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_logits(logits, zx_graph_rep: ZXGraphRepresentation):\n",
    "    action_features = zx_graph_rep.node_features[:, 5:12] # action features should be [pivot?, lcomp?, bialgebra?, fusion?, supp?, color?, stop?] color is always possible ofc\n",
    "    masked_logits = logits.masked_fill(action_features == 0, 0)\n",
    "    return masked_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7dc18-66a4-4a0c-a133-03a06942ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(env, policy_net, optimizer, num_episodes, name, gamma=0.99, verbose=False, save_results=True, comparative=False):\n",
    "    # check if the folder exists first\n",
    "    if save_results:\n",
    "        directory = os.path.dirname(f\"results/{name}/figs/\")\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    num_qubits = env.num_qubits\n",
    "    num_gates = env.num_gates\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = []\n",
    "    pyzx_results = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = ZXGraphRepresentation(env.reset())\n",
    "\n",
    "        if comparative:\n",
    "            original_graph = state.g.copy()\n",
    "            original_verts = len(original_graph.vertices())\n",
    "            zx.full_reduce(original_graph)\n",
    "            pyzx_reward = original_verts - len(original_graph.vertices())\n",
    "        \n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "\n",
    "        done = False\n",
    "        epsilon = 1e-8\n",
    "        while not done:\n",
    "            action_probs = policy_net(state.get_graph_data())\n",
    "            # print(f\"action_probs: {action_probs}\")\n",
    "            # env.render()\n",
    "            # mask impossible actions\n",
    "            masked_logits = mask_logits(action_probs, state)\n",
    "            # print(f\"masked_logits: {masked_logits}\")\n",
    "            # here we want to flatten the tensor into 1D\n",
    "            flattened_probs = torch.flatten(masked_logits)\n",
    "            # then normalize all of the probabilities\n",
    "            # check to see if there are no valid actions\n",
    "            probsum = torch.sum(flattened_probs)\n",
    "            if probsum != 0:\n",
    "                normalized_probs = flattened_probs / torch.sum(flattened_probs)\n",
    "\n",
    "                normalized_probs = torch.clamp(normalized_probs, min=0.0)  # Clamp negative values to 0\n",
    "                normalized_probs[torch.isnan(normalized_probs)] = epsilon  # Replace NaNs with epsilon\n",
    "                normalized_probs[torch.isinf(normalized_probs)] = epsilon  # Replace infs with epsilon\n",
    "                \n",
    "                # Re-normalize after the corrections to ensure valid probabilities\n",
    "                normalized_probs = normalized_probs / torch.sum(normalized_probs + epsilon)\n",
    "                # print(f\"normalized_probs: {normalized_probs}\")\n",
    "                action_index = torch.multinomial(normalized_probs, 1).item()\n",
    "                node_index = action_index // 7\n",
    "                action_type = action_index % 7 # [0: pivot, 1: lcomp, 2: bialg, 3: fusion, 4: supp, 5: color, 6: stop]\n",
    "    \n",
    "                # map actions to action data\n",
    "                action_map = {0: 'pivot', 1: 'lcomp', 2: 'bialg', 3: 'fusion', 4: 'supp', 5: 'color', 6: 'stop'}\n",
    "                valid_actions = env.possible_actions\n",
    "                selected_action = None\n",
    "                for action, action_data in valid_actions:\n",
    "                    if action == action_map[action_type]:\n",
    "                        if action == 'pivot':\n",
    "                            # a pivot match is a 4-tuple\n",
    "                            if node_index in action_data:\n",
    "                                selected_action = (action, action_data)\n",
    "                                break\n",
    "                        elif action == 'lcomp':\n",
    "                            # an lcomp match is (vertex, neighbors)\n",
    "                            temp_vert, _ = action_data\n",
    "                            if temp_vert == node_index:\n",
    "                                selected_action = (action, action_data)\n",
    "                                break\n",
    "                        elif action == 'bialg':\n",
    "                            # a bialg match is a 4-tuple (v1, v2, neighbors_of_v1,neighbors_of_v2)\n",
    "                            v1, v2, _, _ = action_data\n",
    "                            if v1 == node_index or v2 == node_index:\n",
    "                                selected_action = (action, action_data)\n",
    "                                break\n",
    "                        elif action == 'fusion':\n",
    "                            # a fusion match is just a tuple\n",
    "                            if node_index in action_data:\n",
    "                                selected_action = (action, action_data)\n",
    "                                break\n",
    "                        elif action == 'supp':\n",
    "                            # a supp match is a 4-tuple\n",
    "                            v1, v2, _, _ = action_data\n",
    "                            if v1 == node_index or v2 == node_index:\n",
    "                                selected_action = (action, action_data)\n",
    "                                break\n",
    "                        elif action == 'color':\n",
    "                            # color match is a single vertex\n",
    "                            if node_index == action_data:\n",
    "                                selected_action = (action, action_data)\n",
    "                                break\n",
    "                        elif action == 'stop':\n",
    "                            selected_action = 'stop'\n",
    "                            break\n",
    "\n",
    "                # print(f\"SELECTED ACTION: {selected_action}\")\n",
    "                if selected_action != None and selected_action != 'stop':\n",
    "                    # env.render()\n",
    "                    new_g, reward, done, _ = env.step(selected_action)\n",
    "                    # copy the current step as well\n",
    "                    current_step = env.current_step\n",
    "                    env = ZXEnv(new_g.copy(),num_qubits,num_gates,MAX_STEPS=env.MAX_STEPS)\n",
    "                    env.current_step = current_step\n",
    "        \n",
    "                    log_prob = torch.log(normalized_probs[action_index])\n",
    "                    log_probs.append(log_prob)\n",
    "                    rewards.append(reward)\n",
    "        \n",
    "                    state = ZXGraphRepresentation(new_g.copy())\n",
    "                    #print(\"Updated state\")\n",
    "                elif selected_action == 'stop':\n",
    "                    reward = 0\n",
    "                    log_prob = torch.log(normalized_probs[action_index])\n",
    "                    log_probs.append(log_prob)\n",
    "                    rewards.append(reward)\n",
    "                    done = True\n",
    "                else:\n",
    "                    done = True\n",
    "            else:\n",
    "                done = True\n",
    "                #print(f\"Done with episode {episode}\")\n",
    "\n",
    "        # compute the discounted rewards\n",
    "        discounted_rewards = []\n",
    "        R = 0\n",
    "        for r in reversed(rewards):\n",
    "            R = r+gamma*R\n",
    "            discounted_rewards.insert(0, R)\n",
    "\n",
    "        discounted_rewards = torch.tensor(discounted_rewards)\n",
    "\n",
    "        if discounted_rewards.numel() > 1:  # Ensure there are enough elements\n",
    "            discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9)\n",
    "        else:\n",
    "            # If there's only one or zero elements, just skip normalization\n",
    "            discounted_rewards = discounted_rewards - discounted_rewards.mean()  # Center the rewards but no division by std\n",
    "        \n",
    "        \n",
    "        # compute the policy loss\n",
    "        policy_loss = []\n",
    "        for log_prob, R in zip(log_probs, discounted_rewards):\n",
    "            policy_loss.append((-log_prob * R).reshape(1))\n",
    "        if len(policy_loss) > 0:\n",
    "            policy_loss = torch.cat(policy_loss)\n",
    "            # update the policy network\n",
    "            optimizer.zero_grad()           # Clears the gradients from the previous iteration\n",
    "            total_loss = policy_loss.sum()   # Sums all the individual losses\n",
    "            total_loss.backward()            # Backpropagates the loss to compute gradients\n",
    "            optimizer.step()                 # Updates the policy network's weights using the optimizer        \n",
    "            \n",
    "            # monitor\n",
    "            total_reward = sum(rewards)\n",
    "            if verbose:\n",
    "                print(f\"EPISODE: {episode}, TOTAL REWARD: {total_reward}, TOTAL LOSS: {total_loss.item()}\")\n",
    "            results.append({\n",
    "                'episode': episode,\n",
    "                'rewards': rewards,\n",
    "                'log_probs': log_probs,\n",
    "                'policy_loss': policy_loss,\n",
    "                'total_reward': total_reward,\n",
    "                'total_loss': total_loss.item()\n",
    "            })\n",
    "            if comparative:\n",
    "                pyzx_results.append({\n",
    "                    'episode': episode,\n",
    "                    'reward': pyzx_reward\n",
    "                })\n",
    "                \n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Stopped too early. Skipping...\")\n",
    "        \n",
    "\n",
    "        # handle outputs\n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate the average time per episode\n",
    "        avg_time_per_episode = elapsed_time / episode if episode > 0 else elapsed_time\n",
    "        \n",
    "        # Estimate remaining time\n",
    "        episodes_remaining = num_episodes - episode\n",
    "        estimated_time_remaining = avg_time_per_episode * episodes_remaining\n",
    "        \n",
    "        # Convert elapsed time and estimated remaining time to readable format\n",
    "        elapsed_str = str(datetime.timedelta(seconds=int(elapsed_time)))\n",
    "        remaining_str = str(datetime.timedelta(seconds=int(estimated_time_remaining)))\n",
    "        \n",
    "        # Print the progress on the same line\n",
    "        if not verbose:\n",
    "            sys.stdout.write(f\"\\rEpisode: {episode}/{num_episodes} | \"\n",
    "                         f\"Elapsed time: {elapsed_str} | \"\n",
    "                         f\"Estimated time to completion: {remaining_str}\")\n",
    "        \n",
    "    \n",
    "        # Flush the output to ensure it is displayed immediately\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # note to self: add chosen action, possible actions, action probs...\n",
    "    \n",
    "    # save results\n",
    "    if save_results:\n",
    "        torch.save(policy_net.state_dict(), f\"results/{name}/{name}.pth\")\n",
    "        with open(f\"results/{name}/training_progression.txt\", 'w') as f:\n",
    "            for entry in results:\n",
    "                f.write(f\"Episode: {entry['episode']}, Rewards: {entry['rewards']}, Log Probs: {entry['log_probs']}, Total Reward: {entry['total_reward']}, Total Loss: {entry['total_loss']}\\n\")\n",
    "\n",
    "        print(f\"\\nModel saved at results/{name}.\")\n",
    "    print(\"\\n\")\n",
    "    if comparative:\n",
    "        return results, pyzx_results\n",
    "    else:\n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea16aeb-9c15-475d-aace-2685bfd6c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the data\n",
    "def create_plots(results, experiment_name, verbose=False, save_plots=True, comparative=False):\n",
    "    plt.ioff()\n",
    "    # Extract the data\n",
    "    episodes = [result['episode'] for result in results]\n",
    "    total_rewards = [result['total_reward'] for result in results]\n",
    "    total_losses = [result['total_loss'] for result in results]\n",
    "    \n",
    "    # Create a figure for plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot total rewards over episodes\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st plot\n",
    "    plt.plot(episodes, total_rewards, label='Total Reward', color='blue')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot total losses over episodes\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd plot\n",
    "    plt.plot(episodes, total_losses, label='Total Loss', color='red')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Total Loss over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"results/{experiment_name}/figs/raw_plot.png\")\n",
    "    if verbose:\n",
    "        plt.show()\n",
    "\n",
    "    # smoothed plots\n",
    "\n",
    "    # Define a simple moving average function\n",
    "    def moving_average(data, window_size=10):\n",
    "        return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "    \n",
    "    # Apply moving average to smooth the data (window_size can be adjusted)\n",
    "    smoothed_rewards = moving_average(total_rewards, window_size=10)\n",
    "    smoothed_losses = moving_average(total_losses, window_size=10)\n",
    "    \n",
    "    # Adjust the episode range after smoothing (because the moving average reduces data points)\n",
    "    smoothed_episodes = episodes[:len(smoothed_rewards)]\n",
    "    \n",
    "    # Plot the smoothed results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Smoothed rewards\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(smoothed_episodes, smoothed_rewards, label='Smoothed Total Reward', color='blue')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Smoothed Total Reward over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Smoothed losses\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(smoothed_episodes, smoothed_losses, label='Smoothed Total Loss', color='red')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Smoothed Total Loss over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"results/{experiment_name}/figs/smoothed_plot.png\")\n",
    "    if verbose:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # Assuming episodes, total_rewards, and total_losses are arrays\n",
    "    episodes = np.array(episodes)\n",
    "    rewards = np.array(total_rewards)\n",
    "    losses = np.array(total_losses)\n",
    "    \n",
    "    # Lowess smoothing for rewards\n",
    "    smoothed_rewards = lowess(rewards, episodes, frac=0.05)  # frac controls the smoothing span (0.05 = 5%)\n",
    "    \n",
    "    # Lowess smoothing for losses\n",
    "    smoothed_losses = lowess(losses, episodes, frac=0.05)\n",
    "    \n",
    "    # Plotting the data with Lowess centerline\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot for rewards with Lowess\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(episodes, rewards, label='Total Reward', color='blue', alpha=0.3)\n",
    "    plt.plot(smoothed_rewards[:, 0], smoothed_rewards[:, 1], label='Lowess Centerline', color='red')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward with Lowess Centerline')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot for losses with Lowess\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(episodes, losses, label='Total Loss', color='orange', alpha=0.3)\n",
    "    plt.plot(smoothed_losses[:, 0], smoothed_losses[:, 1], label='Lowess Centerline', color='green')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Total Loss with Lowess Centerline')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"results/{experiment_name}/figs/lowess_centerline.png\")\n",
    "    if verbose:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8dd7a-d6a2-4a3b-83fb-793ec1608c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots_comp(results, pyzx_results, experiment_name, verbose=False, save_plots=True):\n",
    "    plt.ioff()\n",
    "    \n",
    "    # Extract the data from results\n",
    "    episodes = [result['episode'] for result in results]\n",
    "    total_rewards = [result['total_reward'] for result in results]\n",
    "    total_losses = [result['total_loss'] for result in results]\n",
    "    \n",
    "    # Extract the data from pyzx_results\n",
    "    pyzx_episodes = [result['episode'] for result in pyzx_results]\n",
    "    pyzx_rewards = [result['reward'] for result in pyzx_results]\n",
    "    \n",
    "    # Create a figure for plotting rewards and losses\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot total rewards over episodes (both results and pyzx_results)\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st plot\n",
    "    plt.plot(episodes, total_rewards, label='Total Reward (RL)', color='blue')\n",
    "    plt.plot(pyzx_episodes, pyzx_rewards, label='Total Reward (PyZX)', color='green')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot total losses over episodes (only for results, as pyzx_results has no loss)\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd plot\n",
    "    plt.plot(episodes, total_losses, label='Total Loss', color='red')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Total Loss over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"results/{experiment_name}/figs/raw_plot_comparison.png\")\n",
    "    if verbose:\n",
    "        plt.show()\n",
    "\n",
    "    # Smoothed plots\n",
    "    \n",
    "    # Define a simple moving average function\n",
    "    def moving_average(data, window_size=10):\n",
    "        return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "    \n",
    "    # Apply moving average to smooth the data (window_size can be adjusted)\n",
    "    smoothed_rewards = moving_average(total_rewards, window_size=10)\n",
    "    smoothed_pyzx_rewards = moving_average(pyzx_rewards, window_size=10)\n",
    "    smoothed_losses = moving_average(total_losses, window_size=10)\n",
    "    \n",
    "    # Adjust the episode range after smoothing\n",
    "    smoothed_episodes = episodes[:len(smoothed_rewards)]\n",
    "    smoothed_pyzx_episodes = pyzx_episodes[:len(smoothed_pyzx_rewards)]\n",
    "    \n",
    "    # Plot the smoothed results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Smoothed rewards (both RL and PyZX)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(smoothed_episodes, smoothed_rewards, label='Smoothed Total Reward (RL)', color='blue')\n",
    "    plt.plot(smoothed_pyzx_episodes, smoothed_pyzx_rewards, label='Smoothed Total Reward (PyZX)', color='green')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Smoothed Total Reward over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Smoothed losses (only for results, as pyzx_results has no loss)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(smoothed_episodes, smoothed_losses, label='Smoothed Total Loss', color='red')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Smoothed Total Loss over Episodes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"results/{experiment_name}/figs/smoothed_plot_comparison.png\")\n",
    "    if verbose:\n",
    "        plt.show()\n",
    "\n",
    "    # LOWESS smoothing for rewards\n",
    "    \n",
    "    # Lowess smoothing for rewards in results and pyzx_results\n",
    "    rewards = np.array(total_rewards)\n",
    "    pyzx_rewards_array = np.array(pyzx_rewards)\n",
    "    smoothed_rewards_lowess = lowess(rewards, episodes, frac=0.05)\n",
    "    smoothed_pyzx_rewards_lowess = lowess(pyzx_rewards_array, pyzx_episodes, frac=0.05)\n",
    "    \n",
    "    # Lowess smoothing for losses in results\n",
    "    losses = np.array(total_losses)\n",
    "    smoothed_losses_lowess = lowess(losses, episodes, frac=0.05)\n",
    "    \n",
    "    # Plotting the data with Lowess centerline\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot for rewards with Lowess (both RL and PyZX)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(episodes, rewards, label='Total Reward (RL)', color='blue', alpha=0.3)\n",
    "    plt.plot(pyzx_episodes, pyzx_rewards, label='Total Reward (PyZX)', color='green', alpha=0.3)\n",
    "    plt.plot(smoothed_rewards_lowess[:, 0], smoothed_rewards_lowess[:, 1], label='Lowess Centerline (RL)', color='red')\n",
    "    plt.plot(smoothed_pyzx_rewards_lowess[:, 0], smoothed_pyzx_rewards_lowess[:, 1], label='Lowess Centerline (PyZX)', color='orange')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward with Lowess Centerline')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot for losses with Lowess (only for results)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(episodes, losses, label='Total Loss', color='orange', alpha=0.3)\n",
    "    plt.plot(smoothed_losses_lowess[:, 0], smoothed_losses_lowess[:, 1], label='Lowess Centerline (Loss)', color='green')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Total Loss with Lowess Centerline')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"results/{experiment_name}/figs/lowess_centerline_comparison.png\")\n",
    "    if verbose:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef0e2c-a9b6-46b1-8328-806c771f39bd",
   "metadata": {},
   "source": [
    "# Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27932d29-2e05-407f-8ed3-f933e8e2ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set qubits and gates\n",
    "num_qubits = 30 # recommended at least 3. Default 5.\n",
    "num_gates = 100 # recommended at least 10. Default 30.     In general, do more qubits and gates.\n",
    "name_notes = \"oct17_test_new_results_txt\"\n",
    "# GNN Network parameters\n",
    "hidden_dim=7\n",
    "num_layers=3\n",
    "# REINFORCE parameters\n",
    "gamma = .90\n",
    "max_steps = 1000\n",
    "num_episodes = 1000\n",
    "comparative = True\n",
    "save_results = False\n",
    "save_plots = True\n",
    "lr = 1e-3\n",
    "\n",
    "g = zx.generate.CNOT_HAD_PHASE_circuit(num_qubits, num_gates).to_graph()\n",
    "env = ZXEnv(g, num_qubits, num_gates, MAX_STEPS=max_steps) # 5,20\n",
    "policy_net = GCNPolicyNetwork(input_dim=12, hidden_dim=hidden_dim, output_dim=7, num_layers=num_layers) # do not change output_dim or input_dim!\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
    "experiment_name = f\"{name_notes}_{num_qubits}q_{num_gates}g\"\n",
    "\n",
    "results = reinforce(env, policy_net, optimizer, name=experiment_name, num_episodes=num_episodes, gamma=gamma, verbose=False, save_results=save_results, comparative=comparative)\n",
    "if results:\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b5462-8f60-4382-965f-e9aa1029e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not comparative:\n",
    "    create_plots(results, experiment_name, verbose=True, save_plots=save_plots)\n",
    "else:\n",
    "    create_plots_comp(results[0], results[1], experiment_name, verbose=True, save_plots=save_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e01c6e-2f45-4c16-aefb-4326b6440661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
